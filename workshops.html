<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category"><br /></div>
<div class="menu-category">Nhat Ho</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publications_type.html">Publications&nbsp;(by&nbsp;type)</a></div>
<div class="menu-item"><a href="publications_topics.html">Publications&nbsp;(by&nbsp;topic)</a></div>
<div class="menu-item"><a href="publications_year.html">Publications&nbsp;(by&nbsp;year)</a></div>
<div class="menu-item"><a href="collaborators.html">Students/&nbsp;Collaborators</a></div>
<div class="menu-item"><a href="workshops.html" class="current">Workshops/&nbsp;Talks/&nbsp;Lectures</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h2 style="color:steelblue;">Workshops Organization:</h2>
<hr>
<ul>
<li><p><a href="https://nips.cc/Conferences/2018/Schedule?showEvent=10916"><i>Integration of Deep Learning Theories</i></a> at NIPS 2018, Palais des Congrès de Montréal, Canada. 
<br />
— Co-organize with Professor Richard Baraniuk, Stephane Mallat, Anima Anandkumar, and Ankit Patel.</p>
</li>
</ul>
<h2 style="color:steelblue;">Conferences, Seminars, and Workshops Presentations:</h2>
<hr>
<ul>
<li><p> [75] On excess mass behavior in Gaussian mixture models with Orlicz Wasserstein distances. <i>Workshop on
"Interpretable inference via principled Bayesian nonparametric approaches in
biomedical research & beyond", National University of Singapore (NUS), 2024 (Invited talk)</i>.</p>
</li>
<li><p> [74] On the multivariate Fourier integral theorem: Statistical and methodological perspectives. <i>International Conference on Econometrics and Statistics (EcoSta),  Tokyo, Japan, 2023 (Invited talk)</i>.</p>
</li>
<li><p> [73] Bayesian sieves and excess mass behaviors in Dirichlet Process mixture models. <i> Workshop on "Approximation Methods in Bayesian Analysis", Centre International de Rencontres Mathématiques, Marseille, France, 2023 (Invited talk)</i>.</p>
</li>
<li><p> [72] On the multivariate Fourier integral theorem: Statistical and methodological perspectives. <i> Vietnam Institute for Advanced Study in Mathematics (VIASM), 2023 (Invited talk)</i>.</p>
</li>
<li><p> [71] On the multivariate Fourier integral theorem: Statistical and methodological perspectives. <i> Summer School Series on Mathematical Statistics and Machine Learning: 2023 School on Bayesian Statistics and Computation, Ho Chi Minh, Viet Nam, 2023 (Invited talk)</i>.</p>
</li>
<li><p> [70] Optimal transport in machine learning and data science. <i>Machine Learning Lunch Seminar, Vanderbilt University, 2023 (Invited talk)</i>.</p>
</li>
<li><p> [69] Probabilistic frameworks for understanding self-attention mechanism in Transformer. <i>Applied Statistics Symposium, International Chinese Statistical Association (ICSA), 2023 (Invited talk)</i>.</p>
</li>
<li><p> [68] Instability, statistical accuracy, and computational efficiency. <i>Applied Math Colloquium, University of California, Los Angeles (UCLA), 2022 (Invited talk)</i>.</p>
</li>
<li><p> [67] Instability, statistical accuracy, and computational efficiency. <i>Workshop on Structured Optimization Models in High-Dimensional Data Analysis, National University of Singapore (NUS), 2022
(Invited talk)</i>.</p>
</li>
<li><p> [66] Optimal transport in machine learning and data science. <i>Optimal Transport and Mean Field games Seminar, University of California, Los Angeles (UCLA), 2022 (Invited talk)</i>.</p>
</li>
<li><p> [65] Statistical and computational perspectives on mixture models. <i>Department Seminar, INRIA, France, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [64] Instability, statistical accuracy, and computational efficiency. <i>Department Seminar, Department of Computer Science, Monash University, Australia, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [63] Statistical and computational perspectives on mixture models. <i>Department Seminar, Department of Mathematics and Statistics, University of Queensland, Australia, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [62] Instability, statistical accuracy, and computational efficiency. <i>Department Seminar, Department of Statistics, University of Sydney, Australia, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [61] Optimal transport in machine learning and data science. <i>Applied Artificial Intelligence Institute, Deakin University, Australia, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [60] Optimal transport in machine learning and data science. <i>Asilomar Conference on Signals, Systems, and Computers, Pacific Grove, CA, USA, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [59] Bayesian sieves and excess mass behaviors in Dirichlet Process mixture models. <i>13th International Conference on Bayesian Nonparametrics, Pontificia Universidad Católica de Chile, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [58] Optimization in machine learning and data science. <i> Department Seminar, College of Engineering and Computer Science, VinUni, Ha Hoi, Vietnam, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [57] Optimal transport in large-scale machine learning applications. <i>FPT Software AI Center, Ha Noi, Viet Nam, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [56] Optimal transport in large-scale machine learning applications. <i>Viettel AI Center, Ha Noi, Viet Nam, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [55] On the multivariate Fourier integral theorem: Statistical and methodological perspectives. <i>International Conference on Econometrics and Statistics (EcoSta),  Kyoto, Japan, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [54] Bayesian sieves and excess mass behaviors in Dirichlet Process mixture models. <i>49th Annual Meeting of the Statistical Society of Canada, Simon Fraser University, Canada, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [53] Bayesian sieves and excess mass behaviors in Dirichlet Process mixture models. <i>Optimal transport meets Bayes" workshop, 16th World Meeting of the International Society for Bayesian Analysis, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [52] On multimarginal partial optimal transport: equivalent forms and computational complexity. <i>SIAM Imaging conference, 2022 (Invited talk)</i>.</p>
</li>
<li><p> [51] Instability, statistical accuracy, and computational efficiency. <i>BLISS Seminar, Department of Electrical Engineering and Computer Sciences, UC Berkeley, 2021 (Invited talk)</i>.</p>
</li>
<li><p> [50] On optimal transport in machine learning and data science. <i>The 13th Asian Conference in Machine Learning, 2021 (Tutorial Talk)</i>.</p>
</li>
<li><p> [49] On optimal transport in machine learning and data science. <i>The Online Asian Machine Learning School, 2021 (Invited talk)</i>.</p>
</li>
<li><p> [48] On optimal transport in machine learning and data science: computational, modeling, and theoretical perspective. <i>INFORMS, 2021 (Invited talk)</i>.</p>
</li>
<li><p> [47] Statistical efficiency of parameter estimation in generalized contaminated models. <i>International Indian Statistical Association (IISA) Conference, 2021 (Invited talk)</i>.</p>
</li>
<li><p> [46] Statistical efficiency of parameter estimation in generalized contaminated models. <i>International Chinese Statistical Association (ICSA), Xi'an University, Xi’an, China, 2021 (Invited talk - Cancelled due to COVID-19)</i>.</p>
</li>
<li><p> [45] Statistical efficiency of parameter estimation in generalized contaminated models. <i>International Conference on Econometrics and Statistics (EcoSta), Yonsei University, Seoul, South Korea, 2021 (Invited talk)</i>.</p>
</li>
<li><p> [44] Statistical and computational perspectives on latent variable models. <i>Department of Decision Sciences at Bocconi University, Italy, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [43] Convergence rates for Gaussian mixtures of experts. <i>International Indian Statistical Association (IISA) Conference, University of Illinois at Chicago, 2020 (Invited talk - Cancelled due to COVID-19)</i>.</p>
</li>
<li><p> [42] Statistical and computational perspectives on latent variable models. <i>Young Data Science Researcher Seminar, ETH Zurich, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [41] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Biostatistics, University of California, Berkeley, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [40] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics and Data Science, CMU, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [39] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, University of California, Los Angeles, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [38] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics and Data Science, Cornell University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [37] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, Rutgers University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [36] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, Purdue University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [35] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Data Science, University of California, San Diego, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [34] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Data Science, John Hopskins University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [33] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, University of 
Wisconsin, Madison, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [32] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, Duke University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [31] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistical Science, University of Toronto, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [30] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics and Data Sciences, University of Texas, Austin, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [29] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, University of Illinois, Urbana-Champaign, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [28] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Booth School of Management, University of Southern California, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [27] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Data Science and Operation Research, University of Southern California, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [26] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, University of Southern California, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [25] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, North Carolina State University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [24] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, University of Minnesota, Twin Cities, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [23] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Krannert School of Management, Purdue University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [22] Statistical and computational perspectives on latent variable models. <i>Department Seminar, Department of Statistics, Pennsylvania State University, 2020 (Invited talk)</i>.</p>
</li>
<li><p> [21] On multilayer latent variable models: Computational and statistical perspectives. <i>Mathematics of Data and Decisions Seminar, Department of Mathematics, UC Davis, 2019 (Invited talk)</i>.</p>
</li>
<li><p> [20] On optimal transport in machine learning and statistics: Computational, modeling, and theoretical perspectives. <i>Research seminar, VinAI Research, Ha Noi, 2019 (Invited talk)</i>.</p>
</li>
<li><p> [19] Statistical and computational perspective of mixture and hierarchical models. <i>BLISS Seminar, Department of EECS, UC Berkeley, 2019 (Invited talk)</i>.</p>
</li>
<li><p> [18] Singularity structures of mixture models: Statistical and computational perspective. <i>Joint Statistical Meetings (JSM), Denver, Colorado, 2019 (Invited talk)</i>.</p>
</li>
<li><p> [17] On efficient optimal transport: an analysis of greedy and accelerated mirror descent algorithms. <i>International Conference on Machine Learning (ICML), Long Beach, CA, 2019</i>.</p>
</li>
<li><p> [16] Singularity structures of mixture models: Statistical and computational perspective. <i>Department
Seminar, Department of Electrical Engineering and Computer Sciences, Rice, November, 2018,
Houston, Texas (Invited talk)</i>.</p>
</li>
<li><p> [15] Singularity structures of parameter estimation in finite mixtures of distributions. <i>Joint Stanford and Berkeley Applied Math Event, November 2018, University of California, Berkeley (Invited talk)</i>.</p>
</li>
<li><p> [14] Singularity Structure of Parameter Space and Posterior Contraction in Finite Mixture Models.  <i>Joint Statistical Meetings (JSM), August, 2017, Baltimore, Maryland (Invited talk)</i>.</p>
</li>
<li><p> [13] Singularity structures and parameter estimation behavior in finite mixtures of distributions. <i>Nonparametric Statistics Workshop: Integration of Theory, Methods, and Applications, October, 2016, Ann Arbor, Michigan</i>.</p>
</li>
<li><p> [12] Singularity structures and impacts on parameter estimation in finite mixtures of distributions. <i>Shannon Centennial Symposium, September, 2016, Ann Arbor, Michigan</i>.</p>
</li>
<li><p> [11] Singularity structures and parameter estimation behavior in finite mixtures of distributions. <i>Joint Statistical Meetings (JSM), August, 2016, Chicago, Illinois</i>.</p>
</li>
<li><p> [10] Singularity structures and parameter estimation behavior in finite mixtures of distributions. <i>Conference on Statistical Learning and Data Science, June, 2016, University of North Carolina at the Chapel Hill</i>.</p>
</li>
<li><p> [9] Singularity structures and parameter estimation behavior in finite mixtures of distributions. <i>Statistical Machine Learning Student Workshop, June, 2016, University of Michigan, Ann Arbor</i>. </p>
</li>
<li><p> [8] Singularity structures and parameter estimation in mixtures of skew normal distributions. <i>Michigan Student Symposium for Interdisciplinary Statistical
Sciences (MSSISS), March, 2016, Ann Arbor, MI</i>.</p>
</li>
<li><p> [7] Weak identifiability and convergence rate of mixing measures in over-fitted Gaussian mixture models. <i>Student Seminar, Department of Statistics, University of Michigan, January, 2016, Ann Arbor, Michigan</i>.</p>
</li>
<li><p> [6] Intrinsic difficulties for the inference of mixing measures in finite mixtures of
univariate skew normal distributions. <i>From Industrial Statistics to Data Science, October, 2015, Ann Arbor, Michigan</i>.</p>
</li>
<li><p> [5] Posterior concentration of mixing parameters in some weakly identifiable finite
mixture models. <i>10th Conference on Bayesian Nonparametrics, June, 2015, Raleigh,
North Carolina</i>.</p>
</li>
<li><p> [4] Weak identifiability and optimal rate of convergence of mixing measures in over-fitted Gaussian mixture models. <i>Statistical Machine Learning Student Workshop, June, 2015, University of
Michigan, Ann Arbor</i>.</p>
</li>
<li><p> [3] Weak identifiability and optimal rate of convergence of mixing measures in
over-fitted Gaussian mixture models. <i>NSF Conference - Statistics for Complex
Systems, June, 2015, Madison, Wisconsin</i>.</p>
</li>
<li><p> [2] Optimal convergence rate of parameter estimation in overfitted finite Gaussian
mixture models. <i>Michigan Student Symposium for Interdisciplinary Statistical
Sciences (MSSISS), March, 2015, Ann Arbor, MI</i>.</p>
</li>
<li><p> [1] Identifiability and convergence rate of parameter estimations in exact-fitted finite
mixture models. <i>Statistical Machine Learning Student Workshop, June, 2014, University of
Michigan, Ann Arbor</i>.</p>
</li>
</ul>
<h2 style="color:steelblue;">Talk Slides</h2>
<hr>
<ul>
<li><p><a href="Optimal_Transport.pdf"><font color=blue size=+0.3> Optimal Transport in Large-Scale Machine Learning Applications </font></a>.</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2020-08-10 20:31:45 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
